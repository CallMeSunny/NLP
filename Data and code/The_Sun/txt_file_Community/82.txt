Facebook suicide livestream videos stay up until the person dies – so onlookers have a chance to intervene
https://www.thesun.co.uk/https://www.thesun.co.uk/tech/6026705/facebook-suicide-videos-live-stream-help/
11th April 2018, 5:40 pm
FACEBOOK only takes down live-streamed suicide videos AFTER a person has killed themselves – giving onlookers a chance to intervene – The Sun has learned.
A senior Facebook exec said that the policy is in place so to protect people, potentially saving users' lives.
Reuters4 Facebook worked with the Samaritans charity to help develop its content policies
Facebook policy chief Monika Bickert leads a global team that manages the policies for what can be shared on the social network.
Her team works to a strict set of Community Standards that help Facebook Content Reviewers (who have the power to delete posts) moderate the website.
She deals with a host of sensitive issues, including how to react to racist posts, terrorist propaganda, and even posts relating to suicide.
But while racist and terrorist content will always be deleted, some suicide content is intentionally left lingering on the website – for user protection.
4 The livestreaming Facebook Live service was launched to the public in January 2017
How Facebook deals with suicide posts
Monika told The Sun: "If somebody is promoting self-harm or celebrating suicide we'll remove it."
"But if someone is posting a cry for help we would leave it up, as it is an opportunity for someone to intervene."
By leaving these posts up, it can help users who are going through difficulties in life to engage with friends and family – and potentially get help.
Facebook works with a number of charities – including Britain's Samaritans – to develop policies like this.
Similarly, Facebook also won't shut down live videos on Facebook Live where people are threatening to kill themselves.
Instead the company will leave it up for "intervention", in the hope that someone may be able to help – or alert the authorities.
However, if a person does indeed take their own life on Facebook Live, the video will then be taken down immediately so that it can't be watched back later on.
Facebook also tweaked its tools to combat inappropriate videos on Facebook Live.
4 Facebook hopes to have more than 20,000 staff working on safety and security by the end of the year
Monika said that the original Live interface didn't quickly allow reviewers to go back through videos that had been reported.
But it's now possible for reviewers to easily scan Live videos.
The system also flags up times for when people (1) stopped watching the video and (2) reported the video, to make it easier to find offending bits of long Facebook Live videos.
Using machines to police Facebook
Facebook has a number of automated systems to help deal with bad content on videos.
For instance, if a child sexual exploitation clip is uploaded and then taken down, the system will remember.
That way, if someone tries to upload the same video again in the future, it'll automatically be blocked.
And law enforcement authorities will be notified about the incident.
Getty Images - Getty4 More than two billion people use Facebook at least once a month
Monika also said that Facebook's machine systems "are getting good at recognising" terrorist propaganda.
For instance, Facebook systems can now detect what an image of an ISIS soldier on a battlefield looks like.
But that doesn't mean it'll necessarily be deleted.
Using language processing technology, Facebook can automatically work out the context.
So if the ISIS image is being shared to show that the soldiers are bad, it'll flag it as safe content.
But if it's being used to promote Daesh, it'll be flagged as inappropriate.
Language is hugely important when tracking down dodgy posts on Facebook.
For instance, Facebook won't ban you if you call Israel evil.
MOST READ IN TECHCORE OF THE PROBLEM? Apple engineer says pressure to design iPhone is reason I’m divorced GRAM SLAM Instagram leaks 'private details' of 49MILLION users – including phone numbers LatestHUNG UP EE back up after five HOUR outage that left thousands unable to make calls ExclusiveNO WEI! EE, O2 and Vodafone slammed for selling Huawei phones 'that might not work' ONE GIANT LEAK Secret Nasa plans for lunar base and 37 rocket launches to the Moon 'leaked' SELL SELL SELL! Huawei owner panic as '100s try to sell phone' – with prices falling by 80% 
But Monika said that Facebook will delete your post if you call Israeli people evil.
According to the policy boss, Facebook "draws the line at attacking people".
Working out context can be tough – Facebook gets millions of reports every week.
These reported posts can be from all around the world, in dozens of different languages.
To help deal with this, Facebook has more than 7,500 content reviewers based around the world, to add a human element to the robot flagging.
These reviewers get training on Facebook's Community Standards, and then specialise on a specific topic – like German hate speech.
By the end of the year, Facebook plans to have 20,000 people working across safety and security.
Mark Zuckerberg reflects back on the history of Facebook and says he is sorry for all 'mistakes' during his testimony to the US Senate 
Some of those will be staff taking part in policy development meetings.
These take place every two weeks, and are presented to a "geographically diverse" selection of employees from different divisions inside Facebook.
Monika's team put tough questions to them around difficult policy problems Facebook is having.
And together they work out how to change the Community Standards to better tackle subjects like bullying or racism online.
But with two billion (and growing) users globally, it's only going to get harder.
Do you think Facebook has the right approach to privacy? Let us know in the comments.

If you are affected by any of the issues raised in this article, please call the Samaritans on (free) 116123 or 020 7734 2800.
Facebook also worked with the Samaritans to launch additional tools to help create a safe space on Facebook where people struggling to cope – as well as their friends and family – can find advice, resources and emotional support: www.facebook.com/help/suicideprevention


We pay for your stories! Do you have a story for The Sun Online news team? Email us at tips@the-sun.co.uk or call 0207 782 4368 . We pay for videos too. Click here to upload yours.


